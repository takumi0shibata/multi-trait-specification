{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from typing import Optional, Literal\n",
    "from utils import load_asap_dataset, load_toefl_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "\n",
    "def mts_scoring(essay, prompt, scoring_criteria, model, tokenizer):\n",
    "    \"\"\"MTS (Multi-Trait Specialization) に基づくエッセイ採点.\"\"\"\n",
    "\n",
    "    # Define system prompt template\n",
    "    system_prompt_template = \"\"\"You are a member of the English essay writing test evaluation committee. Four teachers will be provided with a [Prompt] and an [Essay] written by a student in response to the [Prompt]. Each teacher will score the essays based on different dimensions of writing quality. Your specific responsibility is to score the essays in terms of \"{trait}\". {trait_desc} Focus on the content of the [Essay] and the [Scoring Rubric] to determine the score.\"\"\"\n",
    "\n",
    "    # Define initial user prompt template\n",
    "    user_prompt_template = \"\"\"\n",
    "    [Prompt]\n",
    "    {prompt}\n",
    "    (end of [Prompt])\n",
    "    [Essay]\n",
    "    {essay}\n",
    "    (end of [Essay])\n",
    "    Q. List the quotations from the [Essay] that are relevant to \"{trait}\" and evaluate whether each quotation is well-written or not.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define scoring user prompt template\n",
    "    scoring_prompt_template = \"\"\"\n",
    "    [Scoring Rubric]\n",
    "    **{trait}**:\n",
    "    {criteria}\n",
    "    (end of [Scoring Rubric])\n",
    "    Q. Based on the [Scoring Rubric] and the quotations you found, how would you rate the \"{trait}\" of this essay? Assign a score from 0 to 10, strictly following the [Output Format] below.\n",
    "    [Output Format]\n",
    "    Score: <score>insert ONLY the numeric score (from 0 to 10) here</score>\n",
    "    (End of [Output Format])\n",
    "    \"\"\"\n",
    "    \n",
    "    gen_config = GenerationConfig(\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.1,\n",
    "        do_sample=True\n",
    "    )\n",
    "    trait_scores = []\n",
    "    for info in scoring_criteria:\n",
    "        # Create initial messages\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt_template.format(trait=info['name'], trait_desc=info['description'])},\n",
    "            {\"role\": \"user\", \"content\": user_prompt_template.format(prompt=prompt, essay=essay, trait=info['name'])}\n",
    "        ]\n",
    "\n",
    "        chat = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "        inputs = tokenizer(chat, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        gen_config = GenerationConfig(\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.1,\n",
    "            do_sample=True\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            output_tokens = model.generate(**inputs, generation_config=gen_config)\n",
    "\n",
    "        response_1 = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "        # Add scoring prompt to messages\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response_1})\n",
    "        messages.append({\n",
    "            \"role\": \"user\", \n",
    "            \"content\": scoring_prompt_template.format(\n",
    "                trait=info['name'],\n",
    "                criteria=info['scoring_criteria']\n",
    "            )\n",
    "        })\n",
    "\n",
    "        # Generate response for scoring\n",
    "        chat = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "        inputs = tokenizer(chat, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        gen_config = GenerationConfig(\n",
    "            max_new_tokens=64,\n",
    "            temperature=0.1,\n",
    "            do_sample=True\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            output_tokens = model.generate(**inputs, generation_config=gen_config, return_dict_in_generate=True, output_scores=True)\n",
    "\n",
    "        response_2 = tokenizer.decode(output_tokens.sequences[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
    "\n",
    "        # Extract score\n",
    "        try:\n",
    "            # 数値を抽出するための正規表現パターン\n",
    "            score_pattern = r'\\d+'\n",
    "            match = re.search(score_pattern, response_2)\n",
    "            if match:\n",
    "                score = int(match.group())\n",
    "                trait_scores.append(score)\n",
    "            else:\n",
    "                raise ValueError(\"数値が見つかりませんでした\")\n",
    "        except (ValueError, IndexError) as e:\n",
    "            print(f\"Error extracting score for trait {info['name']}: {e}\")\n",
    "            print(f\"Raw response: {response_2}\")  # デバッグ用\n",
    "            trait_scores.append(-1) # エラー時はとりあえず-1を代入\n",
    "            continue\n",
    "\n",
    "    return trait_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_range(dataset_name, prompt_id):\n",
    "    \"\"\"ASAPデータセットのスコア範囲を取得.\"\"\"\n",
    "    score_ranges = {\n",
    "        \"ASAP\": {\n",
    "            1: (2, 12),\n",
    "            2: (1, 6),\n",
    "            3: (0, 3),\n",
    "            4: (0, 3),\n",
    "            5: (0, 4),\n",
    "            6: (0, 4),\n",
    "            7: (0, 30),\n",
    "            8: (0, 60),\n",
    "        }\n",
    "    }\n",
    "    return score_ranges[dataset_name][prompt_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('outputs/multi-trait-decomposition/asap_rubrics_gpt-4o-mini.json') as f:\n",
    "    all_scoring_criteria = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/takumi/anaconda3/envs/torch/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:833: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/takumi/anaconda3/envs/torch/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d665fa8fba3c41ce89ae07493d32eaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1299 [01:01<22:10:39, 61.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essay_set: 8, scores: [8, 8, 9, 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1299 [01:54<20:17:58, 56.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essay_set: 4, scores: [4, 6, 6, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1299 [02:52<20:33:40, 57.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essay_set: 3, scores: [7, 7, 7, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1299 [03:47<20:17:36, 56.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essay_set: 5, scores: [6, 4, 3, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1299 [04:08<22:18:12, 62.00s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     14\u001b[0m scoring_criteria \u001b[38;5;241m=\u001b[39m all_scoring_criteria[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;132;01m{\u001b[39;00messay_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimensions\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m trait_scores \u001b[38;5;241m=\u001b[39m \u001b[43mmts_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[43messay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring_criteria\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124messay_set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00messay_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrait_scores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m outputs\u001b[38;5;241m.\u001b[39mappend(trait_scores)\n",
      "Cell \u001b[0;32mIn[1], line 65\u001b[0m, in \u001b[0;36mmts_scoring\u001b[0;34m(essay, prompt, scoring_criteria, model, tokenizer)\u001b[0m\n\u001b[1;32m     59\u001b[0m gen_config \u001b[38;5;241m=\u001b[39m GenerationConfig(\n\u001b[1;32m     60\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     61\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     62\u001b[0m     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     63\u001b[0m )\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 65\u001b[0m     output_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m response_1 \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_tokens[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Add scoring prompt to messages\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/transformers/generation/utils.py:2223\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2216\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2217\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2218\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2219\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2220\u001b[0m     )\n\u001b[1;32m   2222\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2223\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2236\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2237\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2242\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2243\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/transformers/generation/utils.py:3214\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3212\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3214\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3216\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3217\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3218\u001b[0m     outputs,\n\u001b[1;32m   3219\u001b[0m     model_kwargs,\n\u001b[1;32m   3220\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3221\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:842\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 842\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    857\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:594\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    583\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    584\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m         position_embeddings,\n\u001b[1;32m    592\u001b[0m     )\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 594\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:333\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    321\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[FlashAttentionKwargs],\n\u001b[1;32m    330\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mFloatTensor, Optional[Tuple[torch\u001b[38;5;241m.\u001b[39mFloatTensor, torch\u001b[38;5;241m.\u001b[39mFloatTensor]]]:\n\u001b[1;32m    331\u001b[0m     residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 333\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m    336\u001b[0m     hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    337\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    338\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    346\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:73\u001b[0m, in \u001b[0;36mLlamaRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     71\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     72\u001b[0m variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 73\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariance_epsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(input_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_auth_token=True\n",
    ")\n",
    "\n",
    "outputs = []\n",
    "for essay_set, essay_id, essay, score in tqdm(df.iter_rows(), total=len(df)):\n",
    "    with open(f\"llm_prompts/ASAP/info/prompt{essay_set}.md\", \"r\") as f:\n",
    "        prompt = f.read()\n",
    "    scoring_criteria = all_scoring_criteria[f'prompt{essay_set}']['dimensions']\n",
    "    trait_scores = mts_scoring(essay, prompt, scoring_criteria, model, tokenizer)\n",
    "    print(f'essay_set: {essay_set}, scores: {trait_scores}')\n",
    "    outputs.append(trait_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' Based on the quotations I found in the essay, I would rate the \"Ideas and Content\" of this essay as a 8 out of 10. The writer presents clear main ideas and uses relevant details to support their argument, but the exploration of the topic could be more in',\n",
       "  ' Based on the quotations I found in the essay, I would rate the \"Organization\" of this essay as a score of 8. The writing has a clear structure, with identifiable sequencing and effective transitions. The ideas are mostly easy to follow, although some transitions could be improved',\n",
       "  ' Based on the quotations I found in the essay, I would rate the \"Voice\" of this essay as a 9. The writer\\'s voice is strong and appropriate, effectively engaging the audience. The writing is expressive and sincere, with a clear sense of the writer',\n",
       "  ' Based on the quotations I found in the essay, I would rate the \"Conventions\" of this essay as follows:\\n\\nScore: 7\\n\\nThe essay contains some errors in conventions, such as inconsistent capitalization (e.g., \"Bell rings. '],\n",
       " [' Based on the scoring rubric provided and the quotations I found, I would rate the \"Understanding of the Text\" of this essay as follows:\\n\\nScore: 5\\n\\nThe essay demonstrates a general understanding of the text, addressing key themes and characters but lacking depth',\n",
       "  ' Based on the scoring rubric provided, I would rate the \"Use of Textual Evidence\" of this essay as follows:\\n\\nScore: 6\\n\\nThe essay provides some relevant examples and quotes from the text to support its claims, but could benefit from more extensive integration of textual evidence',\n",
       "  ' Based on the quotations I found in the essay, I would rate the \"Clarity and Coherence\" of this essay as follows:\\n\\nScore: 6\\n\\nThe essay is generally well-organized, with a clear introduction, body, and conclusion. The author',\n",
       "  ' Based on the scoring rubric provided and the quotations I found in the essay, I would rate the \"Language and Mechanics\" of this essay as follows:\\n\\nScore: 5\\n\\nThe essay contains some errors in grammar and mechanics, but they do not significantly impede understanding']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_299, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>0</th><th>1</th><th>2</th><th>3</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>8</td><td>4</td><td>8</td><td>2</td></tr><tr><td>2</td><td>2</td><td>2</td><td>2</td></tr><tr><td>6</td><td>5</td><td>4</td><td>5</td></tr><tr><td>2</td><td>0</td><td>2</td><td>2</td></tr><tr><td>4</td><td>2</td><td>4</td><td>2</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>4</td><td>4</td><td>4</td><td>4</td></tr><tr><td>4</td><td>2</td><td>2</td><td>2</td></tr><tr><td>2</td><td>2</td><td>2</td><td>2</td></tr><tr><td>5</td><td>4</td><td>6</td><td>4</td></tr><tr><td>8</td><td>6</td><td>6</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_299, 4)\n",
       "┌─────┬─────┬─────┬─────┐\n",
       "│ 0   ┆ 1   ┆ 2   ┆ 3   │\n",
       "│ --- ┆ --- ┆ --- ┆ --- │\n",
       "│ i64 ┆ i64 ┆ i64 ┆ i64 │\n",
       "╞═════╪═════╪═════╪═════╡\n",
       "│ 8   ┆ 4   ┆ 8   ┆ 2   │\n",
       "│ 2   ┆ 2   ┆ 2   ┆ 2   │\n",
       "│ 6   ┆ 5   ┆ 4   ┆ 5   │\n",
       "│ 2   ┆ 0   ┆ 2   ┆ 2   │\n",
       "│ 4   ┆ 2   ┆ 4   ┆ 2   │\n",
       "│ …   ┆ …   ┆ …   ┆ …   │\n",
       "│ 4   ┆ 4   ┆ 4   ┆ 4   │\n",
       "│ 4   ┆ 2   ┆ 2   ┆ 2   │\n",
       "│ 2   ┆ 2   ┆ 2   ┆ 2   │\n",
       "│ 5   ┆ 4   ┆ 6   ┆ 4   │\n",
       "│ 8   ┆ 6   ┆ 6   ┆ 5   │\n",
       "└─────┴─────┴─────┴─────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "results = pl.read_csv(\"outputs/trait_scores_llama3_3B.csv\")\n",
    "results[['0', '1', '2', '3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows_with_negative_one(df):\n",
    "    \"\"\"\n",
    "    Polarsデータフレームから-1を含む行を削除する関数\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pl.DataFrame\n",
    "        入力データフレーム\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pl.DataFrame\n",
    "        -1を含む行が削除されたデータフレーム\n",
    "    \"\"\"\n",
    "    # 各列について-1かどうかをチェックし、行ごとにいずれかの列が-1の場合にTrueとなるマスクを作成\n",
    "    mask = df.select(\n",
    "        pl.fold(\n",
    "            False,\n",
    "            lambda acc, x: acc | (x == -1),\n",
    "            pl.all().exclude([])\n",
    "        )\n",
    "    ).to_series()\n",
    "    \n",
    "    # マスクの否定を使用して-1を含まない行だけを残す\n",
    "    return df.filter(~mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_299, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>essay_set</th><th>essay_id</th><th>essay</th><th>score</th><th>0</th><th>1</th><th>2</th><th>3</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>8</td><td>20826</td><td>&quot; Bell rings.&nbsp;&nbsp;Shuffle, shuffle…</td><td>60</td><td>8</td><td>4</td><td>8</td><td>2</td></tr><tr><td>4</td><td>10064</td><td>&quot;The author concludes the story…</td><td>1</td><td>2</td><td>2</td><td>2</td><td>2</td></tr><tr><td>3</td><td>6127</td><td>&quot;The features of the setting in…</td><td>3</td><td>6</td><td>5</td><td>4</td><td>5</td></tr><tr><td>5</td><td>13551</td><td>&quot;The mood created by the author…</td><td>1</td><td>2</td><td>0</td><td>2</td><td>2</td></tr><tr><td>6</td><td>16370</td><td>&quot;some of the obstacles the buil…</td><td>2</td><td>4</td><td>2</td><td>4</td><td>2</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2</td><td>3090</td><td>&quot;They were talking about thinki…</td><td>3</td><td>4</td><td>4</td><td>4</td><td>4</td></tr><tr><td>3</td><td>6187</td><td>&quot;The features of the setting af…</td><td>1</td><td>4</td><td>2</td><td>2</td><td>2</td></tr><tr><td>7</td><td>18150</td><td>&quot;One @DATE1 @TIME1 I was very p…</td><td>14</td><td>2</td><td>2</td><td>2</td><td>2</td></tr><tr><td>8</td><td>20968</td><td>&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Laug…</td><td>36</td><td>5</td><td>4</td><td>6</td><td>4</td></tr><tr><td>6</td><td>16260</td><td>&quot;In the excerpt from &quot;The Moori…</td><td>4</td><td>8</td><td>6</td><td>6</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_299, 8)\n",
       "┌───────────┬──────────┬─────────────────────────────────┬───────┬─────┬─────┬─────┬─────┐\n",
       "│ essay_set ┆ essay_id ┆ essay                           ┆ score ┆ 0   ┆ 1   ┆ 2   ┆ 3   │\n",
       "│ ---       ┆ ---      ┆ ---                             ┆ ---   ┆ --- ┆ --- ┆ --- ┆ --- │\n",
       "│ i64       ┆ i64      ┆ str                             ┆ i64   ┆ i64 ┆ i64 ┆ i64 ┆ i64 │\n",
       "╞═══════════╪══════════╪═════════════════════════════════╪═══════╪═════╪═════╪═════╪═════╡\n",
       "│ 8         ┆ 20826    ┆  Bell rings.  Shuffle, shuffle… ┆ 60    ┆ 8   ┆ 4   ┆ 8   ┆ 2   │\n",
       "│ 4         ┆ 10064    ┆ The author concludes the story… ┆ 1     ┆ 2   ┆ 2   ┆ 2   ┆ 2   │\n",
       "│ 3         ┆ 6127     ┆ The features of the setting in… ┆ 3     ┆ 6   ┆ 5   ┆ 4   ┆ 5   │\n",
       "│ 5         ┆ 13551    ┆ The mood created by the author… ┆ 1     ┆ 2   ┆ 0   ┆ 2   ┆ 2   │\n",
       "│ 6         ┆ 16370    ┆ some of the obstacles the buil… ┆ 2     ┆ 4   ┆ 2   ┆ 4   ┆ 2   │\n",
       "│ …         ┆ …        ┆ …                               ┆ …     ┆ …   ┆ …   ┆ …   ┆ …   │\n",
       "│ 2         ┆ 3090     ┆ They were talking about thinki… ┆ 3     ┆ 4   ┆ 4   ┆ 4   ┆ 4   │\n",
       "│ 3         ┆ 6187     ┆ The features of the setting af… ┆ 1     ┆ 4   ┆ 2   ┆ 2   ┆ 2   │\n",
       "│ 7         ┆ 18150    ┆ One @DATE1 @TIME1 I was very p… ┆ 14    ┆ 2   ┆ 2   ┆ 2   ┆ 2   │\n",
       "│ 8         ┆ 20968    ┆                           Laug… ┆ 36    ┆ 5   ┆ 4   ┆ 6   ┆ 4   │\n",
       "│ 6         ┆ 16260    ┆ In the excerpt from \"The Moori… ┆ 4     ┆ 8   ┆ 6   ┆ 6   ┆ 5   │\n",
       "└───────────┴──────────┴─────────────────────────────────┴───────┴─────┴─────┴─────┴─────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pl.concat([df, results[['0', '1', '2', '3']]], how='horizontal')\n",
    "final = drop_rows_with_negative_one(final)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>essay_set</th><th>essay_id</th><th>essay</th><th>score</th><th>0</th><th>1</th><th>2</th><th>3</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>1299.0</td><td>1299.0</td><td>&quot;1299&quot;</td><td>1299.0</td><td>1299.0</td><td>1299.0</td><td>1299.0</td><td>1299.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>4.163202</td><td>10237.457275</td><td>null</td><td>6.800616</td><td>3.765204</td><td>3.285604</td><td>3.530408</td><td>3.34719</td></tr><tr><td>&quot;std&quot;</td><td>2.143791</td><td>6344.699906</td><td>null</td><td>8.999117</td><td>1.456981</td><td>1.462168</td><td>1.435718</td><td>1.42842</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td><td>1.0</td><td>&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;…</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>2.0</td><td>4404.0</td><td>null</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td></tr><tr><td>&quot;50%&quot;</td><td>4.0</td><td>9934.0</td><td>null</td><td>3.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>4.0</td></tr><tr><td>&quot;75%&quot;</td><td>6.0</td><td>15784.0</td><td>null</td><td>8.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>4.0</td></tr><tr><td>&quot;max&quot;</td><td>8.0</td><td>21599.0</td><td>&quot;“When they come back, Saeng vo…</td><td>60.0</td><td>8.0</td><td>8.0</td><td>8.0</td><td>8.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 9)\n",
       "┌────────────┬───────────┬─────────────┬────────────┬───┬──────────┬──────────┬──────────┬─────────┐\n",
       "│ statistic  ┆ essay_set ┆ essay_id    ┆ essay      ┆ … ┆ 0        ┆ 1        ┆ 2        ┆ 3       │\n",
       "│ ---        ┆ ---       ┆ ---         ┆ ---        ┆   ┆ ---      ┆ ---      ┆ ---      ┆ ---     │\n",
       "│ str        ┆ f64       ┆ f64         ┆ str        ┆   ┆ f64      ┆ f64      ┆ f64      ┆ f64     │\n",
       "╞════════════╪═══════════╪═════════════╪════════════╪═══╪══════════╪══════════╪══════════╪═════════╡\n",
       "│ count      ┆ 1299.0    ┆ 1299.0      ┆ 1299       ┆ … ┆ 1299.0   ┆ 1299.0   ┆ 1299.0   ┆ 1299.0  │\n",
       "│ null_count ┆ 0.0       ┆ 0.0         ┆ 0          ┆ … ┆ 0.0      ┆ 0.0      ┆ 0.0      ┆ 0.0     │\n",
       "│ mean       ┆ 4.163202  ┆ 10237.45727 ┆ null       ┆ … ┆ 3.765204 ┆ 3.285604 ┆ 3.530408 ┆ 3.34719 │\n",
       "│            ┆           ┆ 5           ┆            ┆   ┆          ┆          ┆          ┆         │\n",
       "│ std        ┆ 2.143791  ┆ 6344.699906 ┆ null       ┆ … ┆ 1.456981 ┆ 1.462168 ┆ 1.435718 ┆ 1.42842 │\n",
       "│ min        ┆ 1.0       ┆ 1.0         ┆ …          ┆ … ┆ 0.0      ┆ 0.0      ┆ 0.0      ┆ 0.0     │\n",
       "│ 25%        ┆ 2.0       ┆ 4404.0      ┆ null       ┆ … ┆ 2.0      ┆ 2.0      ┆ 2.0      ┆ 2.0     │\n",
       "│ 50%        ┆ 4.0       ┆ 9934.0      ┆ null       ┆ … ┆ 4.0      ┆ 4.0      ┆ 4.0      ┆ 4.0     │\n",
       "│ 75%        ┆ 6.0       ┆ 15784.0     ┆ null       ┆ … ┆ 4.0      ┆ 4.0      ┆ 4.0      ┆ 4.0     │\n",
       "│ max        ┆ 8.0       ┆ 21599.0     ┆ “When they ┆ … ┆ 8.0      ┆ 8.0      ┆ 8.0      ┆ 8.0     │\n",
       "│            ┆           ┆             ┆ come back, ┆   ┆          ┆          ┆          ┆         │\n",
       "│            ┆           ┆             ┆ Saeng vo…  ┆   ┆          ┆          ┆          ┆         │\n",
       "└────────────┴───────────┴─────────────┴────────────┴───┴──────────┴──────────┴──────────┴─────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_299, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>essay_set</th><th>essay_id</th><th>essay</th><th>score</th><th>0</th><th>1</th><th>2</th><th>3</th><th>total_score</th><th>total_score_iqr</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>6</td><td>16370</td><td>&quot;some of the obstacles the buil…</td><td>2</td><td>4</td><td>2</td><td>4</td><td>2</td><td>12</td><td>12</td></tr><tr><td>6</td><td>16486</td><td>&quot;The builders had to go through…</td><td>2</td><td>2</td><td>2</td><td>2</td><td>4</td><td>10</td><td>10</td></tr><tr><td>6</td><td>16303</td><td>&quot;On December 11, 1929, Al Smith…</td><td>4</td><td>4</td><td>6</td><td>4</td><td>4</td><td>18</td><td>18</td></tr><tr><td>6</td><td>16051</td><td>&quot;The builders of the Empire Sta…</td><td>4</td><td>4</td><td>4</td><td>4</td><td>4</td><td>16</td><td>16</td></tr><tr><td>6</td><td>15892</td><td>&quot;In the excerpt, The Mooring Ma…</td><td>3</td><td>4</td><td>4</td><td>2</td><td>4</td><td>14</td><td>14</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>5</td><td>13021</td><td>&quot;The mood created by the author…</td><td>3</td><td>4</td><td>4</td><td>5</td><td>4</td><td>17</td><td>17</td></tr><tr><td>5</td><td>13425</td><td>&quot;The mood that was created by t…</td><td>2</td><td>4</td><td>4</td><td>4</td><td>6</td><td>18</td><td>18</td></tr><tr><td>5</td><td>12439</td><td>&quot;The story, &quot;Narciso Rodriguez&quot;…</td><td>3</td><td>4</td><td>4</td><td>4</td><td>4</td><td>16</td><td>16</td></tr><tr><td>5</td><td>11951</td><td>&quot;Reading this article expresses…</td><td>3</td><td>4</td><td>4</td><td>2</td><td>2</td><td>12</td><td>12</td></tr><tr><td>5</td><td>13058</td><td>&quot;The mood the author created in…</td><td>2</td><td>4</td><td>2</td><td>4</td><td>2</td><td>12</td><td>12</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_299, 10)\n",
       "┌───────────┬──────────┬───────────────────┬───────┬───┬─────┬─────┬─────────────┬─────────────────┐\n",
       "│ essay_set ┆ essay_id ┆ essay             ┆ score ┆ … ┆ 2   ┆ 3   ┆ total_score ┆ total_score_iqr │\n",
       "│ ---       ┆ ---      ┆ ---               ┆ ---   ┆   ┆ --- ┆ --- ┆ ---         ┆ ---             │\n",
       "│ i64       ┆ i64      ┆ str               ┆ i64   ┆   ┆ i64 ┆ i64 ┆ i64         ┆ i64             │\n",
       "╞═══════════╪══════════╪═══════════════════╪═══════╪═══╪═════╪═════╪═════════════╪═════════════════╡\n",
       "│ 6         ┆ 16370    ┆ some of the       ┆ 2     ┆ … ┆ 4   ┆ 2   ┆ 12          ┆ 12              │\n",
       "│           ┆          ┆ obstacles the     ┆       ┆   ┆     ┆     ┆             ┆                 │\n",
       "│           ┆          ┆ buil…             ┆       ┆   ┆     ┆     ┆             ┆                 │\n",
       "│ 6         ┆ 16486    ┆ The builders had  ┆ 2     ┆ … ┆ 2   ┆ 4   ┆ 10          ┆ 10              │\n",
       "│           ┆          ┆ to go through…    ┆       ┆   ┆     ┆     ┆             ┆                 │\n",
       "│ 6         ┆ 16303    ┆ On December 11,   ┆ 4     ┆ … ┆ 4   ┆ 4   ┆ 18          ┆ 18              │\n",
       "│           ┆          ┆ 1929, Al Smith…   ┆       ┆   ┆     ┆     ┆             ┆                 │\n",
       "│ 6         ┆ 16051    ┆ The builders of   ┆ 4     ┆ … ┆ 4   ┆ 4   ┆ 16          ┆ 16              │\n",
       "│           ┆          ┆ the Empire Sta…   ┆       ┆   ┆     ┆     ┆             ┆                 │\n",
       "│ 6         ┆ 15892    ┆ In the excerpt,   ┆ 3     ┆ … ┆ 2   ┆ 4   ┆ 14          ┆ 14              │\n",
       "│           ┆          ┆ The Mooring Ma…   ┆       ┆   ┆     ┆     ┆             ┆                 │\n",
       "│ …         ┆ …        ┆ …                 ┆ …     ┆ … ┆ …   ┆ …   ┆ …           ┆ …               │\n",
       "│ 5         ┆ 13021    ┆ The mood created  ┆ 3     ┆ … ┆ 5   ┆ 4   ┆ 17          ┆ 17              │\n",
       "│           ┆          ┆ by the author…    ┆       ┆   ┆     ┆     ┆             ┆                 │\n",
       "│ 5         ┆ 13425    ┆ The mood that was ┆ 2     ┆ … ┆ 4   ┆ 6   ┆ 18          ┆ 18              │\n",
       "│           ┆          ┆ created by t…     ┆       ┆   ┆     ┆     ┆             ┆                 │\n",
       "│ 5         ┆ 12439    ┆ The story,        ┆ 3     ┆ … ┆ 4   ┆ 4   ┆ 16          ┆ 16              │\n",
       "│           ┆          ┆ \"Narciso          ┆       ┆   ┆     ┆     ┆             ┆                 │\n",
       "│           ┆          ┆ Rodriguez\"…       ┆       ┆   ┆     ┆     ┆             ┆                 │\n",
       "│ 5         ┆ 11951    ┆ Reading this      ┆ 3     ┆ … ┆ 2   ┆ 2   ┆ 12          ┆ 12              │\n",
       "│           ┆          ┆ article           ┆       ┆   ┆     ┆     ┆             ┆                 │\n",
       "│           ┆          ┆ expresses…        ┆       ┆   ┆     ┆     ┆             ┆                 │\n",
       "│ 5         ┆ 13058    ┆ The mood the      ┆ 2     ┆ … ┆ 4   ┆ 2   ┆ 12          ┆ 12              │\n",
       "│           ┆          ┆ author created    ┆       ┆   ┆     ┆     ┆             ┆                 │\n",
       "│           ┆          ┆ in…               ┆       ┆   ┆     ┆     ┆             ┆                 │\n",
       "└───────────┴──────────┴───────────────────┴───────┴───┴─────┴─────┴─────────────┴─────────────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = final.with_columns(\n",
    "    (pl.col('0') + pl.col('1') + pl.col('2') + pl.col('3')).alias('total_score')\n",
    ")\n",
    "# essay_setごとにIQRでクリッピング\n",
    "def clip_by_iqr(series, lower_limit=1.5, upper_limit=1.5):\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - lower_limit * iqr\n",
    "    upper_bound = q3 + upper_limit * iqr\n",
    "    return series.clip(lower_bound, upper_bound)\n",
    "\n",
    "clipped = final.group_by('essay_set').map_groups(lambda group: \n",
    "    group.with_columns([\n",
    "        pl.Series(clip_by_iqr(group['total_score'])).alias('total_score_iqr')\n",
    "    ])\n",
    ")\n",
    "clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>essay_set</th><th>essay_id</th><th>essay</th><th>score</th><th>0</th><th>1</th><th>2</th><th>3</th><th>total_score</th><th>total_score_iqr</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>1299.0</td><td>1299.0</td><td>&quot;1299&quot;</td><td>1299.0</td><td>1299.0</td><td>1299.0</td><td>1299.0</td><td>1299.0</td><td>1299.0</td><td>1299.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>4.163202</td><td>10237.457275</td><td>null</td><td>6.800616</td><td>3.765204</td><td>3.285604</td><td>3.530408</td><td>3.34719</td><td>13.928406</td><td>13.91378</td></tr><tr><td>&quot;std&quot;</td><td>2.143791</td><td>6344.699906</td><td>null</td><td>8.999117</td><td>1.456981</td><td>1.462168</td><td>1.435718</td><td>1.42842</td><td>5.042832</td><td>4.993859</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td><td>1.0</td><td>&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;…</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>2.0</td><td>4404.0</td><td>null</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>10.0</td><td>10.0</td></tr><tr><td>&quot;50%&quot;</td><td>4.0</td><td>9934.0</td><td>null</td><td>3.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>14.0</td><td>14.0</td></tr><tr><td>&quot;75%&quot;</td><td>6.0</td><td>15784.0</td><td>null</td><td>8.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>16.0</td><td>16.0</td></tr><tr><td>&quot;max&quot;</td><td>8.0</td><td>21599.0</td><td>&quot;“When they come back, Saeng vo…</td><td>60.0</td><td>8.0</td><td>8.0</td><td>8.0</td><td>8.0</td><td>31.0</td><td>30.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 11)\n",
       "┌────────────┬───────────┬────────────┬───────────┬───┬──────────┬─────────┬───────────┬───────────┐\n",
       "│ statistic  ┆ essay_set ┆ essay_id   ┆ essay     ┆ … ┆ 2        ┆ 3       ┆ total_sco ┆ total_sco │\n",
       "│ ---        ┆ ---       ┆ ---        ┆ ---       ┆   ┆ ---      ┆ ---     ┆ re        ┆ re_iqr    │\n",
       "│ str        ┆ f64       ┆ f64        ┆ str       ┆   ┆ f64      ┆ f64     ┆ ---       ┆ ---       │\n",
       "│            ┆           ┆            ┆           ┆   ┆          ┆         ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪════════════╪═══════════╪═══╪══════════╪═════════╪═══════════╪═══════════╡\n",
       "│ count      ┆ 1299.0    ┆ 1299.0     ┆ 1299      ┆ … ┆ 1299.0   ┆ 1299.0  ┆ 1299.0    ┆ 1299.0    │\n",
       "│ null_count ┆ 0.0       ┆ 0.0        ┆ 0         ┆ … ┆ 0.0      ┆ 0.0     ┆ 0.0       ┆ 0.0       │\n",
       "│ mean       ┆ 4.163202  ┆ 10237.4572 ┆ null      ┆ … ┆ 3.530408 ┆ 3.34719 ┆ 13.928406 ┆ 13.91378  │\n",
       "│            ┆           ┆ 75         ┆           ┆   ┆          ┆         ┆           ┆           │\n",
       "│ std        ┆ 2.143791  ┆ 6344.69990 ┆ null      ┆ … ┆ 1.435718 ┆ 1.42842 ┆ 5.042832  ┆ 4.993859  │\n",
       "│            ┆           ┆ 6          ┆           ┆   ┆          ┆         ┆           ┆           │\n",
       "│ min        ┆ 1.0       ┆ 1.0        ┆ …         ┆ … ┆ 0.0      ┆ 0.0     ┆ 0.0       ┆ 0.0       │\n",
       "│ 25%        ┆ 2.0       ┆ 4404.0     ┆ null      ┆ … ┆ 2.0      ┆ 2.0     ┆ 10.0      ┆ 10.0      │\n",
       "│ 50%        ┆ 4.0       ┆ 9934.0     ┆ null      ┆ … ┆ 4.0      ┆ 4.0     ┆ 14.0      ┆ 14.0      │\n",
       "│ 75%        ┆ 6.0       ┆ 15784.0    ┆ null      ┆ … ┆ 4.0      ┆ 4.0     ┆ 16.0      ┆ 16.0      │\n",
       "│ max        ┆ 8.0       ┆ 21599.0    ┆ “When     ┆ … ┆ 8.0      ┆ 8.0     ┆ 31.0      ┆ 30.0      │\n",
       "│            ┆           ┆            ┆ they come ┆   ┆          ┆         ┆           ┆           │\n",
       "│            ┆           ┆            ┆ back,     ┆   ┆          ┆         ┆           ┆           │\n",
       "│            ┆           ┆            ┆ Saeng vo… ┆   ┆          ┆         ┆           ┆           │\n",
       "└────────────┴───────────┴────────────┴───────────┴───┴──────────┴─────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipped.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1001137/4011932663.py:19: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  group.with_columns([\n",
      "/tmp/ipykernel_1001137/4011932663.py:19: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  group.with_columns([\n",
      "/tmp/ipykernel_1001137/4011932663.py:19: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  group.with_columns([\n",
      "/tmp/ipykernel_1001137/4011932663.py:19: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  group.with_columns([\n",
      "/tmp/ipykernel_1001137/4011932663.py:19: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  group.with_columns([\n",
      "/tmp/ipykernel_1001137/4011932663.py:19: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  group.with_columns([\n",
      "/tmp/ipykernel_1001137/4011932663.py:19: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  group.with_columns([\n",
      "/tmp/ipykernel_1001137/4011932663.py:19: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  group.with_columns([\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_299, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>essay_set</th><th>essay_id</th><th>essay</th><th>score</th><th>0</th><th>1</th><th>2</th><th>3</th><th>total_score</th><th>total_score_iqr</th><th>normalized_score</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>3</td><td>6127</td><td>&quot;The features of the setting in…</td><td>3</td><td>6</td><td>5</td><td>4</td><td>5</td><td>20</td><td>20</td><td>2</td></tr><tr><td>3</td><td>7471</td><td>&quot;Well if the setting relates to…</td><td>1</td><td>2</td><td>2</td><td>2</td><td>2</td><td>8</td><td>8</td><td>0</td></tr><tr><td>3</td><td>7241</td><td>&quot;The features of the setting ef…</td><td>2</td><td>4</td><td>4</td><td>2</td><td>2</td><td>12</td><td>12</td><td>0</td></tr><tr><td>3</td><td>6619</td><td>&quot;I think that there were many t…</td><td>3</td><td>4</td><td>4</td><td>4</td><td>4</td><td>16</td><td>16</td><td>1</td></tr><tr><td>3</td><td>6547</td><td>&quot;He’s on a very hot climate, in…</td><td>2</td><td>2</td><td>2</td><td>2</td><td>2</td><td>8</td><td>8</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2</td><td>3461</td><td>&quot;No books should be taken off t…</td><td>3</td><td>4</td><td>4</td><td>4</td><td>4</td><td>16</td><td>16</td><td>3</td></tr><tr><td>2</td><td>3479</td><td>&quot;A library is a place to go and…</td><td>3</td><td>2</td><td>4</td><td>4</td><td>2</td><td>12</td><td>12</td><td>2</td></tr><tr><td>2</td><td>3172</td><td>&quot;Should books, magazines, movie…</td><td>4</td><td>4</td><td>4</td><td>4</td><td>4</td><td>16</td><td>16</td><td>3</td></tr><tr><td>2</td><td>3501</td><td>&quot;There should not be any style …</td><td>4</td><td>4</td><td>4</td><td>4</td><td>4</td><td>16</td><td>16</td><td>3</td></tr><tr><td>2</td><td>3090</td><td>&quot;They were talking about thinki…</td><td>3</td><td>4</td><td>4</td><td>4</td><td>4</td><td>16</td><td>16</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_299, 11)\n",
       "┌───────────┬──────────┬──────────────┬───────┬───┬─────┬─────────────┬──────────────┬─────────────┐\n",
       "│ essay_set ┆ essay_id ┆ essay        ┆ score ┆ … ┆ 3   ┆ total_score ┆ total_score_ ┆ normalized_ │\n",
       "│ ---       ┆ ---      ┆ ---          ┆ ---   ┆   ┆ --- ┆ ---         ┆ iqr          ┆ score       │\n",
       "│ i64       ┆ i64      ┆ str          ┆ i64   ┆   ┆ i64 ┆ i64         ┆ ---          ┆ ---         │\n",
       "│           ┆          ┆              ┆       ┆   ┆     ┆             ┆ i64          ┆ i64         │\n",
       "╞═══════════╪══════════╪══════════════╪═══════╪═══╪═════╪═════════════╪══════════════╪═════════════╡\n",
       "│ 3         ┆ 6127     ┆ The features ┆ 3     ┆ … ┆ 5   ┆ 20          ┆ 20           ┆ 2           │\n",
       "│           ┆          ┆ of the       ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│           ┆          ┆ setting in…  ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│ 3         ┆ 7471     ┆ Well if the  ┆ 1     ┆ … ┆ 2   ┆ 8           ┆ 8            ┆ 0           │\n",
       "│           ┆          ┆ setting      ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│           ┆          ┆ relates to…  ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│ 3         ┆ 7241     ┆ The features ┆ 2     ┆ … ┆ 2   ┆ 12          ┆ 12           ┆ 0           │\n",
       "│           ┆          ┆ of the       ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│           ┆          ┆ setting ef…  ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│ 3         ┆ 6619     ┆ I think that ┆ 3     ┆ … ┆ 4   ┆ 16          ┆ 16           ┆ 1           │\n",
       "│           ┆          ┆ there were   ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│           ┆          ┆ many t…      ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│ 3         ┆ 6547     ┆ He’s on a    ┆ 2     ┆ … ┆ 2   ┆ 8           ┆ 8            ┆ 0           │\n",
       "│           ┆          ┆ very hot     ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│           ┆          ┆ climate, in… ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│ …         ┆ …        ┆ …            ┆ …     ┆ … ┆ …   ┆ …           ┆ …            ┆ …           │\n",
       "│ 2         ┆ 3461     ┆ No books     ┆ 3     ┆ … ┆ 4   ┆ 16          ┆ 16           ┆ 3           │\n",
       "│           ┆          ┆ should be    ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│           ┆          ┆ taken off t… ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│ 2         ┆ 3479     ┆ A library is ┆ 3     ┆ … ┆ 2   ┆ 12          ┆ 12           ┆ 2           │\n",
       "│           ┆          ┆ a place to   ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│           ┆          ┆ go and…      ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│ 2         ┆ 3172     ┆ Should       ┆ 4     ┆ … ┆ 4   ┆ 16          ┆ 16           ┆ 3           │\n",
       "│           ┆          ┆ books,       ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│           ┆          ┆ magazines,   ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│           ┆          ┆ movie…       ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│ 2         ┆ 3501     ┆ There should ┆ 4     ┆ … ┆ 4   ┆ 16          ┆ 16           ┆ 3           │\n",
       "│           ┆          ┆ not be any   ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│           ┆          ┆ style …      ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│ 2         ┆ 3090     ┆ They were    ┆ 3     ┆ … ┆ 4   ┆ 16          ┆ 16           ┆ 3           │\n",
       "│           ┆          ┆ talking      ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│           ┆          ┆ about        ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "│           ┆          ┆ thinki…      ┆       ┆   ┆     ┆             ┆              ┆             │\n",
       "└───────────┴──────────┴──────────────┴───────┴───┴─────┴─────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_score_range(dataset_name, prompt_id):\n",
    "    \"\"\"ASAPデータセットのスコア範囲を取得.\"\"\"\n",
    "    score_ranges = {\n",
    "        \"ASAP\": {\n",
    "            1: (2, 12),\n",
    "            2: (1, 6),\n",
    "            3: (0, 3),\n",
    "            4: (0, 3),\n",
    "            5: (0, 4),\n",
    "            6: (0, 4),\n",
    "            7: (0, 30),\n",
    "            8: (0, 60),\n",
    "        }\n",
    "    }\n",
    "    return score_ranges[dataset_name][prompt_id]\n",
    "\n",
    "# essay_setごとにスコアを正規化（min-max変換）\n",
    "normalized = clipped.group_by('essay_set').map_groups(lambda group: \n",
    "    group.with_columns([\n",
    "        pl.col('total_score_iqr').map_elements(\n",
    "            lambda x: int(\n",
    "                (x - group['total_score_iqr'].min()) * (get_score_range(\"ASAP\", group['essay_set'][0])[1] - get_score_range(\"ASAP\", group['essay_set'][0])[0]) / (group['total_score_iqr'].max() - group['total_score_iqr'].min()) + get_score_range(\"ASAP\", group['essay_set'][0])[0]\n",
    "            )\n",
    "        ).alias('normalized_score')\n",
    "    ])\n",
    ")\n",
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWK scores by essay set:\n",
      "shape: (8, 2)\n",
      "┌───────────┬──────────┐\n",
      "│ essay_set ┆ qwk      │\n",
      "│ ---       ┆ ---      │\n",
      "│ i64       ┆ f64      │\n",
      "╞═══════════╪══════════╡\n",
      "│ 1         ┆ 0.356677 │\n",
      "│ 2         ┆ 0.442847 │\n",
      "│ 3         ┆ 0.236312 │\n",
      "│ 4         ┆ 0.441607 │\n",
      "│ 5         ┆ 0.453303 │\n",
      "│ 6         ┆ 0.275021 │\n",
      "│ 7         ┆ 0.346879 │\n",
      "│ 8         ┆ 0.210931 │\n",
      "└───────────┴──────────┘\n",
      "スピアマンの順位相関係数 by essay set:\n",
      "shape: (8, 2)\n",
      "┌───────────┬───────────────┐\n",
      "│ essay_set ┆ spearman_corr │\n",
      "│ ---       ┆ ---           │\n",
      "│ i64       ┆ f64           │\n",
      "╞═══════════╪═══════════════╡\n",
      "│ 1         ┆ 0.383062      │\n",
      "│ 2         ┆ 0.519228      │\n",
      "│ 3         ┆ 0.509863      │\n",
      "│ 4         ┆ 0.630465      │\n",
      "│ 5         ┆ 0.693902      │\n",
      "│ 6         ┆ 0.465543      │\n",
      "│ 7         ┆ 0.327896      │\n",
      "│ 8         ┆ 0.423483      │\n",
      "└───────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# essay_setごとにQWKとスピアマンの順位相関係数を計算\n",
    "qwk_scores = []\n",
    "spearman_scores = []\n",
    "for essay_set in normalized['essay_set'].unique():\n",
    "    subset = normalized.filter(pl.col('essay_set') == essay_set)\n",
    "    qwk = cohen_kappa_score(\n",
    "        subset['score'].to_numpy(),\n",
    "        subset['normalized_score'].to_numpy(),\n",
    "        weights='quadratic',\n",
    "        labels=np.arange(get_score_range(\"ASAP\", essay_set)[0], get_score_range(\"ASAP\", essay_set)[1] + 1)\n",
    "    )\n",
    "    spearman_corr, _ = spearmanr(subset['score'].to_numpy(), subset['normalized_score'].to_numpy())\n",
    "    qwk_scores.append({\n",
    "        'essay_set': essay_set,\n",
    "        'qwk': qwk\n",
    "    })\n",
    "    spearman_scores.append({\n",
    "        'essay_set': essay_set,\n",
    "        'spearman_corr': spearman_corr\n",
    "    })\n",
    "\n",
    "qwk_df = pl.DataFrame(qwk_scores)\n",
    "spearman_df = pl.DataFrame(spearman_scores)\n",
    "print(\"QWK scores by essay set:\")\n",
    "print(qwk_df)\n",
    "print(\"スピアマンの順位相関係数 by essay set:\")\n",
    "print(spearman_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34544701334307726"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwk_df['qwk'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4941801932936464"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearman_df['spearman_corr'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
